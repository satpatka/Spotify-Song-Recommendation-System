---
title: 'Spotify Song Recommendation System'
author: "Keya Satpathy"
date: "4/24/2020"
output: 
  html_document:
    toc: true
    toc_float: 
      collapsed: false
      smooth_scroll: false
    number_sections: true
---
<font size = 4>

<h1><span style="color: green;">1.INTRODUCTION</span></h1>

<div style="text-align: justify">

<h2><span style="color: green;">1.1 Background</span></h2>
Spotify is one of the biggest digital music, podcast, and video streaming service in the world that gives access to millions of songs and other content from artists all over the world. Not only does Spotify gives us access to good songs everywhere (work, home, in the car), it has also introduced us to artists that we would never have listened to before and in genres that we had never experienced. Spotify uses very advanced technology to track and identify each song uploaded to its platform. 

</div>

<div style="text-align:center">
<img src="https://www.theindianwire.com/wp-content/uploads/2019/02/spotify-1024x576.jpg" alt="picture" border="0" height="350" width="750">
</div>

<div style="text-align: justify">

The Spotify database provides an interesting look into their listening data. Not just the popularity of tracks, but also features of the tracks they have in their library is recorded in their database. In this project, we have analyzed a track's popularity based on several audio features provided in the dataset and found answer to 'Can we predict a track's popularity from key features about the song?' We have also done a custom analysis based on user's listening profile which shall enable Spotify to stock up similar hit tracks more on their platform and let go off songs that are not much popular among the listeners.

We are considering you as a Spotify user. So as a Spotify user, won't you be impressed if you can get a list of the most popular songs tailored to your taste without having to manually search for them extensively? Also, won't you be a happy and recurring customer if you keep on getting a list of latest top music, divided by genre and have easy access to recently released music? We will be solving for providing easy access to popular songs and that is the reason, you, as a Spotify user should be interested.

</div>

<h2><span style="color: green;">1.2 Methodology Used</span></h2>

<div style="text-align: justify">

We have analyzed relationship between popularity and different audio features and genres through a detaoled EDA. Then we have performed clustering analysis using K-means method to provide song recommendation based on recent user listening on Spotify. Here we have extracted a pattern from the clusters and determined how does each cluster differ. This helped us predict the most and least popular clusters. Finally we have created a 'Song Recommendation System'.

</div>

<h2><span style="color: green;">1.3 Proposed Analytical Approach</span></h2>

<div style="text-align: justify">

K-means clustering has provided information about customer listening behavior which shall help Spotify upsell, cross-sell or combine both to increase profit. Using this method, we have analyzed correlation between songs in a cluster and their popularity rate.

After we have clustered the songs, we have build a song recommendation system to enable listeners get effective suggestions regarding next best songs according to their taste.

</div>

<h2><span style="color: green;">1.4 Usefulness of Analysis</span></h2>

<div style="text-align: justify">

Consumer of our analysis would be Spotify's programming team. Our analysis shall enable the team to upsell, cross-sell or combine both to increase profit. Having a better understanding of different clusters shall enable Spotify to make a better targeted content distribution, leading to reduced churn rate.

For example, if the team knows that 30% of customers who listens to track A also listens to track B, Spotify can market track B to customers shortly after they listen to track A to speed up that process and capture those who might not have otherwise considered listening to track B. Also, for those customers who do not know of track B, getting suggestions will make them happy and impressed. This is how our analysis would help Spotify in providing better services to their consumers and keep them ahead of the curve.

</div>

<h1><span style="color: green;">2.PACKAGES USED</span></h1>
```{r, warning=FALSE, message=FALSE}

#install.packages("tidyverse")
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("plotly")
#install.packages("corrplot")
#install.packages("factoextra")
#install.packages("plyr")
#install.packages("RColorBrewer")
#install.packages("funModeling")
#install.packages("knitr")



library(tidyverse)
library(dplyr)
library(ggplot2)
library(plotly)
library(corrplot)
library(factoextra)
library(plyr)
library(RColorBrewer)
library(funModeling)
library(knitr)
```
<div style="text-align: justify">

<b>tidyverse</b> - for interacting with data through subsetting, transformation, visualization, etc.

<b>dplyr</b> - for data manipulation in R by combining, selecting, grouping, subsetting and transforming all or parts of dataset

<b>ggplot2</b> - for declaratively creating graphics, based on The Grammar of Graphics

<b>plotly</b> - for creating interactive web-based graphs via the open source JavaScript graphing library plotly.js

<b>corrplot</b> - for visualizing correlation matrices and confidence intervals

<b>factoextra</b> - to extract and visualize the output of multivariate data analyses and simplifying some clustering 

<b>plyr</b> - to split data apart, do stuff to it, and mash it back together for simplifying control to the input and output data format

<b>RColorBrewer</b> - to choose sensible colour schemes for figures in R

<b>funModeling</b> - for some cool 'dataViz'

</div>

<h1><span style="color: green;">3.DATA PREPARATION</span></h1>

<h2><span style="color: green;">3.1 Data Source</span></h2>

<div style="text-align: justify">

The dataset used for this project is the Spotify song list prepared by Zaheen Hamidani which we got from kaggle. (https://www.kaggle.com/zaheenhamidani/ultimate-spotify-tracks-db)

</div>

<h2><span style="color: green;">3.2 Data Information</span></h2>

<div style="text-align: justify">

Originally, the dataset was created by Zaheen Hamidani and uploaded to Kaggle in July 2019. Alternately, it is also available in a R package version 2.1.1 [Spotify R package](https://www.rcharlie.com/spotifyr/). Charlie Thompson, Josia Parry, Donal Phipps, and Tom Wolff authored this package to make it easier to get data or general metadata around songs from Spotify's API. It allows to enter an artist's name and retrieve their entire audio history (collection of all songs) in seconds, along with Spotify's audio features and track/album popularity metrics.

The primary purpose of the data was to analyze the behaviour between valence and all the measures that Spotify API gives for every track. Approximately 10,000 songs were selected per genre and there are 26 genres. But, the same data can also be used to analyze different statistics and obtain other useful information.

There is not much peculiarity in the data. It is moderately clean with only 15 missing values. Since every track made is unique is some sense, we have not done any missing value imputation and have just removed them.

</div>

<h2><span style="color: green;">3.3 Data Importing</span></h2>

<div style="text-align: justify">

First, we will load the Spotify songs dataset into R to kickstart with the analysis.The dataset has been imported using the read.csv function and saved as "spotify".

```{r}
set.seed(13232767)
spotify <- read.csv("spotify_songs.csv")
```


```{r}
glimpse(spotify)
```

Our dataset has 32,833 observations and 23 variables.

</div>

<h2><span style="color: green;">3.4 Data Cleaning</span></h2>

<h3><span style="color: green;">3.4.1 Removing NA's</span></h3>

<div style="text-align: justify">

Using the colSums function, we observe that there are 5 NA's in track_name, track_artist and track_album_name. We have removed the respective observations using the na.omit function.

</div>

```{r}
colSums(is.na(spotify))
```

```{r}
spotify <- na.omit(spotify)
```

<h3><span style="color: green;">3.4.2 Filtering</span></h3>

<div style="text-align: justify">

Filtering for unique tracks and removing all the duplicated tracks using the duplicated function

</div>

```{r}
spotify <- spotify[!duplicated(spotify$track_id),]
```

<h3><span style="color: green;">3.4.3 Transforming Variables</span></h3>

<div style="text-align: justify">

Converting key, mode, genre and sub genre to factors to facilitate our data analysis since that seemed logical observing the type of data these columns contain

```{r}
spotify <- spotify %>%
  mutate(playlist_genre = as.factor(spotify$playlist_genre),
         playlist_subgenre = as.factor(spotify$playlist_subgenre),
         mode = as.factor(mode),
         key = as.factor(key))
```

Converting duration_ms to duration in mins (duration_min) since it is more sensible for the analysis

</div>

```{r}
spotify <- spotify %>% mutate(duration_min = duration_ms/60000)
```

<h3><span style="color: green;">3.4.4 Creating New Variables</span></h3>

<div style="text-align: justify">

For exploring the distribution on popularity, we have made new variables that divide popularity into 4 groups for effective cluster analysis 

</div>

```{r}
spotify <- spotify %>% 
  mutate(popularity_group = as.numeric(case_when(
    ((track_popularity > 0) & (track_popularity < 20)) ~ "1",
    ((track_popularity >= 20) & (track_popularity < 40))~ "2",
    ((track_popularity >= 40) & (track_popularity < 60)) ~ "3",
    TRUE ~ "4"))
    )
table(spotify$popularity_group)

```

<h3><span style="color: green;">3.4.5 Removing Variables</span></h3>

<div style="text-align: justify">

We have removed track_id, track_album_id and playlist_id from the dataset since it is not useful for our analysis. These unique id's have been maintained in the Spotify dataset only to uniquely identify a track in the database.

</div>

```{r}
spotify <- spotify %>% select(-c(track_id, track_album_id, playlist_id))
summary(spotify)
```

<h2><span style="color: green;">3.5 Description of Attributes</span></h2>

<div style="text-align: justify">

Each row indicates 1 song and column contain attributes for each song.The attributes are as follows:

<b>track_id</b> - Track id on spotify

<b>track_name</b> - Title of the song

<b>track_artist</b> - Name of the artist

<b>track_popularity</b> - Measure the popularity from 0 to 100 based on play number of the track

<b>acousticness</b> - Measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.

<b>danceability</b> - Describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.

<b>duration_ms</b> - The duration of the track in milliseconds(ms).

<b>energy</b> - Measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.

<b>instrumentalness</b> - Measure whether a track contains no vocals. 'Ooh' and 'aah' sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly 'vocal'. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.

<b>key</b> - Estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1.

<b>liveness</b> - Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.

<b>loudness</b> - overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 dB.

<b>mode</b> - Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.

<b>speechiness</b> - Detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.

<b>tempo</b> Overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.

<b>valence</b> - Measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).

</div>

<h1><span style="color: green;">4.EXPLORATORY DATA ANALYSIS</span></h1>

<div style="text-align: justify">

The best way to uncover useful information from data that is not self-evident is by performing EDA efficiently. EDA helps us to make sense of our data. Before performing a formal analysis, it is essential to explore a data set. No models can be done without a proper EDA. This will help us to better understand the patterns within the data, detect outliers or anomalous events and find interesting relations among the variables. We have used histograms, boxplots and correlation plot to find such answers.

</div>

<h2><span style="color: green;">4.1 Correlation Plot</span></h2>
```{r}
df1 <- select(spotify, track_popularity, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo)
corrplot(cor(df1))
```

<div style="text-align: justify">

The plot shows popularity does not have strong correlation with track features. But we found some variables have strong correlation with each other, indicating that this dataset has multicollinearity and might not be suitable for various classification algorithms.

</div>

<h2><span style="color: green;">4.2 Histogram</span></h2>

<div style="text-align: justify">

Analyzing data distribution of the audio features

```{r}
spotify_hist <- spotify[,-c(1,2,3,4,5,6,7,8,11,13,20,22)]
plot_num(spotify_hist)
```

From the histograms, we can observe that:

- Majority (85.4323394%) observations have a value no larger than 0.1 in instrumentalness, and this is the reason why the difference between mean and median of instrumentalness is quite large

- Majority of songs listened to have a duration of about 3-4 mins with songs longer than that duration having lower frequency of listeners

- Valence is normally distributed

- Danceability and energy are almost normally distributed

- Majority of the tracks have a loudness level of -5dB

- Majority tracks have speechiness index less than 0.2 indicating that less speechy songs are more favoured by listeners

</div>

<h2><span style="color: green;">4.3 Boxplot</span></h2>

<h3><span style="color: green;">4.3.1 Genre by Energy</span></h3>
```{r}
boxplot(energy~playlist_genre, data=spotify,
        main = "Variation of energy between genres",
        xlab = "Energy",
        ylab = "Genre",
        col = "orange",
        border = "brown",
        horizontal = TRUE,
        notch = TRUE
)
```

EDM songs are highest in energy, as expected!

<h3><span style="color: green;">4.3.2 Genre by Danceability</span></h3>
```{r}
boxplot(danceability~playlist_genre, data=spotify,
        main = "Variation of danceability between genres",
        xlab = "Danceability",
        ylab = "Genre",
        col = "orange",
        border = "brown",
        horizontal = TRUE,
        notch = TRUE
)
```

Rap songs have highest danceability, I knew!

<h3><span style="color: green;">4.3.3 Genre by Liveliness</span></h3>
```{r}
boxplot(danceability~playlist_genre, data=spotify,
        main = "Variation of liveness between genres",
        xlab = "Liveness",
        ylab = "Genre",
        col = "orange",
        border = "brown",
        horizontal = TRUE,
        notch = TRUE
)
```

Rap songs are most lively, obviously!

<h3><span style="color: green;">4.3.4 Genre by Valence</span></h3>
```{r}
boxplot(valence~playlist_genre, data=spotify,
        main = "Variation of valence between genres",
        xlab = "Valence",
        ylab = "Genre",
        col = "orange",
        border = "brown",
        horizontal = TRUE,
        notch = TRUE
)
```

Songs in Latin genre have the highest valence, OK!

<h3><span style="color: green;">4.3.5 Genre by Loudness</span></h3>
```{r}
boxplot(loudness~playlist_genre, data=spotify,
        main = "Variation of loudness between genres",
        xlab = "Loudness",
        ylab = "Genre",
        col = "orange",
        border = "brown",
        horizontal = TRUE,
        notch = TRUE
)
```

Songs in EDM genre are louder in nature, cool!

<h2><span style="color: green;">4.4 Popularity by Accousticness</span></h2>
```{r}
spotify$acousticness.scale <- scale(spotify$acousticness)
spotify %>%
  select(popularity_group, acousticness.scale, playlist_genre) %>%
  group_by(popularity_group)%>%
  filter(!is.na(popularity_group)) %>%
  filter(!is.na(acousticness.scale))%>%
  ggplot(mapping = aes(x = acousticness.scale, y = popularity_group, color = playlist_genre))+
  facet_wrap(~playlist_genre)+
  geom_point()+
  theme_minimal()
```

<div style="text-align: justify">

Accoustiness does not effect track popularity as the level of accousticness has been uniform across all popularity levels.

</div>

<h2><span style="color: green;">4.5 Popularity by Valence</span></h2>
```{r}
spotify%>%
  select(popularity_group, valence, playlist_genre) %>%
  group_by(popularity_group)%>%
  filter(!is.na(popularity_group)) %>%
  filter(!is.na(valence))%>%
  ggplot(mapping = aes(x = popularity_group, y = valence, color = playlist_genre, fill = playlist_genre))+
  geom_bar(stat = 'identity')+
  coord_polar()+
  facet_wrap(~playlist_genre)+
  theme_minimal()
```

<div style="text-align: justify">

Songs with higher valence index are more popular in pop and rap genre and less in edm genre.

</div>

<h2><span style="color: green;">4.6 Energy Distribution</span></h2>
```{r}
spotify$cut_energy <- cut(spotify$energy, breaks = 10)
spotify %>%
  ggplot( aes(x=cut_energy ))+
  geom_bar(width=0.2) +
  coord_flip() +
  scale_x_discrete(name="Energy")  
```

<div style="text-align: justify">

Suppports the findings from the energy histogram. Hence proved that higher energy songs are favoured more by Spotify listeners.

</div>

<h2><span style="color: green;">4.7 Speechiness Distribution</span></h2>
```{r}
spotify$cut_spe <- cut(spotify$speechiness, breaks = 10)
spotify %>%
  ggplot( aes(x=cut_spe ))+
  geom_bar(width=0.2) +
  coord_flip() +
  scale_x_discrete(name="Spechiness")  
```

<div style="text-align: justify">

This graph also supports the findings of our histogram for speechiness. As we all know how we do not like speechier tracks, this affirms our belief that less speechy songs are more favoured by maximum Spotify listeners. So, Spotify does not keep speechier songs in their database.

</div>

<h2><span style="color: green;">4.8 Tempo and Liveness Distribution across Genre</span></h2>
```{r}
spotify$liveness.scale <- scale(spotify$liveness)
spotify$tempo.scale <- scale(spotify$tempo)
spotify %>%
  select(tempo.scale, liveness.scale, playlist_genre) %>%
  group_by(playlist_genre)%>%
  filter(!is.na(tempo.scale)) %>%
  filter(!is.na(liveness.scale))%>%
  ggplot(mapping = aes(x = tempo.scale, y = liveness.scale, color = playlist_genre, fill = playlist_genre))+
  geom_bar(stat = 'identity')+
  coord_polar()+
  theme_minimal()

```

<div style="text-align: justify">

Tempo is way higher for EDM genre compared to the others while Liveness is almost uniformly distributed across all genres.

</div>

<h2><span style="color: green;">4.9 3D Scatter Plot</span></h2>

<h3><span style="color: green;">4.9.1 Track_Popularity vs Danceability vs Energy</span></h3>
```{r}
spotify_arrange <- spotify[order(-spotify$track_popularity),]

 

plot_ly(head(spotify_arrange, n=500), x = ~track_popularity, y = ~danceability, z = ~energy, 
        color = ~playlist_genre, colors = c('magenta', 'green', 'red', 'cyan', 'orange', 'yellow'),size = I(100)) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'track_popularity'),
                      yaxis = list(title = 'danceability'),
                      zaxis = list(title = 'energy')),
         title = "3D Scatter plot: Track_popularity vs Danceability vs Energy",
         showlegend = FALSE)
```

<div style="text-align: justify">

Track poularity is directly related to it's Danceability and Energy quotient; no doubt since majority of Spotify listeners are millenials.

</div>

<h3><span style="color: green;">4.9.2 Track_Popularity vs Genre vs Subgenre</span></h3>
```{r}
spotify_arrange <- spotify[order(-spotify$track_popularity),]

 

plot_ly(head(spotify_arrange, n=500), x = ~track_popularity, y = ~playlist_genre, z = ~playlist_subgenre, 
        color = ~playlist_genre, colors = c('magenta', 'green', 'red', 'cyan', 'orange', 'yellow'),size = I(100)) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'track_popularity'),
                      yaxis = list(title = 'playlist_genre'),
                      zaxis = list(title = 'playlist_subgenre')),
         title = "3D Scatter plot: Track_popularity vs Playlist genre vs Playlisty subgenre",
         showlegend = FALSE)
```

<div style="text-align: justify">

There is an almost uniform distribution between track genre and popularity.

</div>

<h2><span style="color: green;">4.10 Top 10 Artists and their Most Famous Tracks</span></h2>
```{r}
spotify %>%
  select(track_name, track_artist, track_album_name, playlist_genre, track_popularity)%>%
  group_by(track_artist)%>%
  filter(!is.na(track_name))%>%
  filter(!is.na(track_artist))%>%
  filter(!is.na(track_album_name))%>%
  arrange(desc(track_popularity))%>%
  head(n = 10)%>%
  ggplot(mapping = aes(x = track_name, y =  track_artist, color = track_artist, fill = track_artist, size = track_popularity ))+
  geom_point()+
  coord_polar()+
  facet_wrap(~playlist_genre)+
  theme_minimal()+
  labs(x = 'track_name', y = 'track_artist', title = 'Top ten artists of spotify')+
  theme(plot.title = element_text(hjust=0.5),legend.position ='bottom')
```

<div style="text-align: justify">

The top songs are primarily from Pop genre, the most popular song being by the artist 'Tones & I'. Latin and Rap also have one song each featured in top 10.

</div>

<h1><span style="color: green;">5.MODEL BUILDING</span></h1>
 
<h2><span style="color: green;">5.1 Data Clustering</span></h2>

<div style="text-align: justify">

Before performing clustering, we need to scale the numeric variables so as to negate the influence of variables measured on higher scales. The variables that I choose in this analysis for Cluster are as follows:
- Danceability
- Energy
- Loudness
- Speechiness
- Acousticness
- Instrumentalness
- Liveness
- Valence
- Tempo
- Duration_min

Checking the updated dataset since we have certain variables changes for EDA
```{r}
str(spotify)
```

Scaling the numeric variables required for cluster analysis:
```{r}
spotify_scaled <- scale(spotify[,-c(1,2,3,4,5,6,7,8,11,13,20,22,23,24,25,26,27)])
summary(spotify_scaled)
```

</div>

<h3><span style="color: green;">5.1.1 Elbow Method</span></h3>

<div style="text-align: justify">

Determining the optimal number of clusters:
```{r}
wss <- function(data, maxCluster = 9) {
  SSw <- (nrow(data) - 1) * sum(apply(data, 2, var))
  SSw <- vector()
  for (i in 2:maxCluster) {
    SSw[i] <- sum(kmeans(data, centers = i)$withinss)
  }
  plot(1:maxCluster, SSw, type = "o", xlab = "Number of Clusters", ylab = "Within groups sum of squares", pch=19)
}

wss(spotify_scaled)
```

By looking at the plot, we can't see the "Elbow" clearly. But we think it happens at k = 7 since within group sum of squares is not changing significantly after k = 7. So we choose 7 to be number of clusters for this analysis.

</div>

<h3><span style="color: green;">5.1.2 K-means Clustering</span></h3>
```{r}
spotify_kmeans <- kmeans(spotify_scaled, centers = 7)
spotify_kmeans$size

spotify_kmeans$centers

spotify$cluster <- spotify_kmeans$cluster
tail(spotify)
```

<h3><span style="color: green;">5.1.3 Insights</span></h3>

<div style="text-align: justify">

- The size of each cluster (count of each cluster) returns: cluster1 2289, cluster2 3690, cluster3 5635, cluster4 2857, cluster5 4788, cluster6 1776 and cluster 7 7317

- The centers shows the mean value on each of the variable


Plotting using 'factoextra':

</div>
```{r}
fviz_cluster(spotify_kmeans, data=spotify_scaled)
```

<h3><span style="color: green;">5.1.4 Goodness of Fit</span></h3>

<div style="text-align: justify">

We can check it from the following 3 values:

1 - Within Sum of Squares tot.withinss : signifies the 'length' from each observation to its centroid in each cluster

```{r}
spotify_kmeans$tot.withinss
```

2-  Total Sum of Squares totss : signifies the 'length' from each observation to global sample mean

```{r}
spotify_kmeans$totss
```

3 - Between Sum of Squares betweenss : signifies the 'length' from each centroid from each cluster to the global sample mean

```{r}
spotify_kmeans$betweenss
```

Another 'goodness' measure can be signifies with a value of betweenss/totss closer the value to 1 or 100%, the better): `betweenss`/`tot.withinss`

```{r}
((spotify_kmeans$betweenss)/(spotify_kmeans$totss))*100
```

Good cluster has high similarity characteristics in 1 cluster (low WSS) and maximum difference in characteristics between clusters (high BSS). In addition, it can be marked with a BSS / totss ratio that is close to 1 (100%).

From the unsupervised learning analysis above, we can summarize that K-means clustering can be done using this dataset since we have got a reasonable high value for BSS / totss ratio, 40.78%.

Repeating the same exercise multiple times by adjusting with multiple combinations of variables, we are getting the best fit and optimized model by excluding loudness, tempo and duration_min.

Finding what kind of song characterises each clusters in the optimized model:

</div>

```{r,warning=FALSE}
spotify %>% 
  group_by(cluster) %>% 
  summarise_all(mean) %>% 
  select(cluster, acousticness, danceability, energy, instrumentalness, speechiness, valence, liveness)
```
 
<div style="text-align: justify">
 
<h3><span style="color: green;">5.1.5 Characteristics of Clusters</span></h3>
- Cluster 1: Highest danceability, Highest valence
- Cluster 2: Highest energy, Lowest acousticness
- Cluster 3: Lowest instrumentalness, Highest speechiness
- Cluster 4: Lowest speechiness, Lowest liveness
- Cluster 5: Lowest acousticness, Highest liveness  
- Cluster 6: Highest instrumentalness
- Cluster 7: Highest acousticness, Lowest energy, Lowest valence

</div>

<h2><span style="color: green;"> 5.2 Song Recommendation System</span></h2>
 
<div style="text-align: justify">

Now, let's check the which cluster is my favorite song. My favourite track from the list is Memories by Maroon 5.

```{r}
spotify %>% 
  filter(track_name == "Memories - Dillon Francis Remix", track_artist == "Maroon 5")
```

So my favourite song is in cluster 3.

Now I want to try a new genre, r&b. So let's check the best songs which I should try according to my taste in the r&b genre given that my favourite song is Memories by Maroon 5.

</div>

```{r}
spotify %>% 
  filter(cluster == 3, playlist_genre == "r&b") %>% 
  sample_n(5)
```


<h1><span style="color: green;">6.LEARNINGS & KEY TAKEAWAYS</span></h1>

<div style="text-align: justify">

We have also performed association mining on this dataset. We got stuck here due to the large number of unique tracks in dataset and the limited system capacity we processing capacity. From this we learnt that maybe association mining is not fit for a dataset of with large number of unique values. We tried reducing the dataset by deleting random rows but even with 600 rows, we got 520K rules and top 10 rules with 100% confidence level, which is not feasible for analysis. 

From our correlation plot, we observed that variables have strong correlation with each other, indicating that this dataset has multicollinearity. With further deep diving into this matter, we learnt that such types of dataset are not suitable for various classification algorithms. So we dropped our plan for CART (Classification Tree) and Random Forest.

Learning such ML nuances were a major takeaway for us from this project.

</div>